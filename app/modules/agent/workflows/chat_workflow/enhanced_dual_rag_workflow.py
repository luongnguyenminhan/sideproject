"""
Enhanced Dual RAG Workflow for Chat System
T√≠ch h·ª£p Global KB + Conversation KB v·ªõi intelligent routing
"""

import asyncio
import time
import json
import logging
from datetime import datetime, timezone
from typing import Dict, Any, Optional, List

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langgraph.graph import StateGraph, END, START
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.memory import MemorySaver
from sqlalchemy.orm import Session

from .state.workflow_state import AgentState, StateManager
from .config.workflow_config import WorkflowConfig
from .tools.basic_tools import get_tools
from .utils.color_logger import get_color_logger, Colors

logger = get_color_logger(__name__)


class EnhancedDualRAGWorkflow:
	"""Enhanced Chat Workflow v·ªõi Dual RAG system"""

	def __init__(self, db_session: Session, config: Optional[WorkflowConfig] = None):
		"""Initialize enhanced dual RAG workflow"""
		self.start_time = time.time()
		logger.workflow_start(
			'Enhanced Dual RAG Workflow Initialization',
			db_session_type=type(db_session).__name__,
			config_provided=config is not None,
		)

		self.db_session = db_session
		self.config = config or WorkflowConfig.from_env()
		self.config.db_session = db_session

		# Initialize LLM
		self.llm = ChatGoogleGenerativeAI(model=self.config.model_name, temperature=self.config.temperature)

		# Initialize Global KB Service
		self._init_global_kb_service()

		# Build workflow
		self.compiled_graph = self._build_enhanced_workflow()

		logger.success(
			'üöÄ Enhanced Dual RAG Workflow initialized successfully',
			initialization_time=time.time() - self.start_time,
		)

	def _init_global_kb_service(self):
		"""Initialize Global Knowledge Base Service"""
		try:
			from app.modules.agentic_rag.services.global_kb_service import (
				GlobalKBService,
			)

			self.global_kb_service = GlobalKBService(self.db_session)
			logger.info('Global KB Service initialized successfully')
		except Exception as e:
			logger.error(f'Error initializing Global KB Service: {str(e)}')
			self.global_kb_service = None

	def _build_enhanced_workflow(self) -> StateGraph:
		"""Build enhanced workflow v·ªõi dual RAG capabilities"""
		workflow = StateGraph(AgentState)

		# Get enhanced tools including dual RAG tool
		tools = get_tools(self.config)
		tool_node = ToolNode(tools)

		# Add nodes
		workflow.add_node('agent', self._agent_node)
		workflow.add_node('dual_rag_processor', self._dual_rag_processor_node)
		workflow.add_node('tools', tool_node)
		workflow.add_node('response_generator', self._response_generator_node)

		# Add edges
		workflow.add_edge(START, 'agent')
		workflow.add_conditional_edges(
			'agent',
			self._route_agent_decision,
			{
				'dual_rag': 'dual_rag_processor',
				'tools': 'tools',
				'respond': 'response_generator',
			},
		)
		workflow.add_edge('dual_rag_processor', 'response_generator')
		workflow.add_edge('tools', 'agent')
		workflow.add_edge('response_generator', END)

		# Compile v·ªõi memory saver
		checkpointer = MemorySaver()
		return workflow.compile(checkpointer=checkpointer)

	async def _agent_node(self, state: AgentState) -> AgentState:
		"""Main agent node v·ªõi dual RAG routing logic"""
		logger.info('ü§ñ Agent node processing...')

		try:
			messages = state.get('messages', [])
			last_message = messages[-1] if messages else None

			if not last_message:
				return state

			# Analyze message ƒë·ªÉ quy·∫øt ƒë·ªãnh c√≥ c·∫ßn dual RAG hay kh√¥ng
			needs_rag = await self._analyze_message_for_rag(last_message.content)

			if needs_rag:
				# Mark for dual RAG processing
				return {
					**state,
					'need_rag': True,
					'current_node': 'agent',
					'next_action': 'dual_rag',
				}
			else:
				# Direct response ho·∫∑c use tools
				tools = get_tools(self.config)
				llm_with_tools = self.llm.bind_tools(tools)

				response = await llm_with_tools.ainvoke(messages)

				if response.tool_calls:
					return {
						**state,
						'messages': messages + [response],
						'pending_tool_calls': response.tool_calls,
						'next_action': 'tools',
					}
				else:
					return {
						**state,
						'messages': messages + [response],
						'next_action': 'respond',
					}

		except Exception as e:
			logger.error(f'Error in agent node: {str(e)}')
			error_response = AIMessage(content=f'Xin l·ªói, c√≥ l·ªói x·∫£y ra: {str(e)}')
			return {
				**state,
				'messages': state.get('messages', []) + [error_response],
				'next_action': 'respond',
			}

	async def _dual_rag_processor_node(self, state: AgentState) -> AgentState:
		"""Process dual RAG retrieval v√† routing"""
		logger.info('üîç Dual RAG processor node executing...')

		try:
			messages = state.get('messages', [])
			last_message = messages[-1] if messages else None

			if not last_message:
				return state

			# Get conversation metadata
			conv_metadata = state.get('conversation_metadata', {})
			conversation_id = conv_metadata.get('conversation_id', 'default')
			user_id = conv_metadata.get('user_id', 'anonymous')

			# Execute dual RAG using the tool
			from .tools.dual_rag_tool import DualRAGTool

			dual_rag_tool = DualRAGTool(db_session=self.db_session)
			rag_result = dual_rag_tool._run(
				conversation_id=conversation_id,
				user_id=user_id,
				query=last_message.content,
				top_k=5,
			)

			# Parse RAG result
			rag_data = json.loads(rag_result) if isinstance(rag_result, str) else rag_result

			# Update state v·ªõi dual RAG context
			return {
				**state,
				'dual_rag_routing': rag_data.get('routing_decision'),
				'combined_rag_context': rag_data.get('context', ''),
				'global_rag_context': [s for s in rag_data.get('sources', []) if s.get('source_type') == 'global'],
				'conversation_rag_context': [s for s in rag_data.get('sources', []) if s.get('source_type') == 'conversation'],
				'current_node': 'dual_rag_processor',
				'next_action': 'respond',
			}

		except Exception as e:
			logger.error(f'Error in dual RAG processor: {str(e)}')
			return {
				**state,
				'error_context': {'dual_rag_error': str(e)},
				'next_action': 'respond',
			}

	async def _response_generator_node(self, state: AgentState) -> AgentState:
		"""Generate final response v·ªõi RAG context"""
		logger.info('üìù Response generator node executing...')

		try:
			messages = state.get('messages', [])
			combined_context = state.get('combined_rag_context', '')

			# Build enhanced prompt v·ªõi RAG context
			if combined_context:
				system_prompt = f"""B·∫°n l√† AI assistant th√¥ng minh v·ªõi kh·∫£ nƒÉng truy c·∫≠p ki·∫øn th·ª©c t·ª´ nhi·ªÅu ngu·ªìn.

CONTEXT T·ª™ KNOWLEDGE BASES:
{combined_context}

H∆Ø·ªöNG D·∫™N:
- S·ª≠ d·ª•ng th√¥ng tin t·ª´ context ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi
- N·∫øu context kh√¥ng ƒë·ªß, h√£y th·ª´a nh·∫≠n v√† ƒë∆∞a ra c√¢u tr·∫£ l·ªùi t·ªët nh·∫•t c√≥ th·ªÉ
- Lu√¥n cung c·∫•p th√¥ng tin ch√≠nh x√°c v√† h·ªØu √≠ch
- Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát tr·ª´ khi ƒë∆∞·ª£c y√™u c·∫ßu kh√°c
- Ghi r√µ ngu·ªìn th√¥ng tin khi c·∫ßn thi·∫øt (Global KB ho·∫∑c Conversation KB)
"""
			else:
				system_prompt = """B·∫°n l√† AI assistant th√¥ng minh v√† h·ªØu √≠ch.
Tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch ch√≠nh x√°c v√† th√¢n thi·ªán.
S·ª≠ d·ª•ng ti·∫øng Vi·ªát tr·ª´ khi ƒë∆∞·ª£c y√™u c·∫ßu kh√°c."""

			# Generate response
			enhanced_messages = [SystemMessage(content=system_prompt)] + messages
			response = await self.llm.ainvoke(enhanced_messages)

			# Add metadata v·ªÅ RAG usage
			routing_info = state.get('dual_rag_routing', {})
			if routing_info:
				metadata_note = f'\n\n_[S·ª≠ d·ª•ng {routing_info} knowledge base(s)]_'
				response.content += metadata_note

			return {
				**state,
				'messages': messages + [response],
				'current_node': 'response_generator',
			}

		except Exception as e:
			logger.error(f'Error in response generator: {str(e)}')
			error_response = AIMessage(content=f'Xin l·ªói, c√≥ l·ªói trong qu√° tr√¨nh t·∫°o ph·∫£n h·ªìi: {str(e)}')
			return {**state, 'messages': state.get('messages', []) + [error_response]}

	def _route_agent_decision(self, state: AgentState) -> str:
		"""Route based on agent's decision"""
		next_action = state.get('next_action', 'respond')

		logger.info(f'üîÄ Routing decision: {next_action}')

		if next_action == 'dual_rag':
			return 'dual_rag'
		elif next_action == 'tools':
			return 'tools'
		else:
			return 'respond'

	async def _analyze_message_for_rag(self, message_content: str) -> bool:
		"""Ph√¢n t√≠ch message ƒë·ªÉ quy·∫øt ƒë·ªãnh c√≥ c·∫ßn RAG hay kh√¥ng"""
		try:
			# Keywords indicate need for knowledge retrieval
			rag_keywords = [
				'th·∫ø n√†o',
				'l√† g√¨',
				'c√°ch',
				'h∆∞·ªõng d·∫´n',
				'gi·∫£i th√≠ch',
				't·∫°i sao',
				'khi n√†o',
				'·ªü ƒë√¢u',
				'ai',
				'how',
				'what',
				'why',
				'when',
				'where',
				'who',
				'explain',
				'tell me',
				'cv',
				'resume',
				'experience',
				'skill',
				'code',
				'programming',
				'development',
			]

			message_lower = message_content.lower()
			needs_rag = any(keyword in message_lower for keyword in rag_keywords)

			# Ho·∫∑c c√≥ th·ªÉ d√πng LLM ƒë·ªÉ quy·∫øt ƒë·ªãnh ph·ª©c t·∫°p h∆°n
			if not needs_rag and len(message_content) > 50:
				# For longer messages, use LLM to decide
				decision_prompt = f"""
                Ph√¢n t√≠ch c√¢u h·ªèi sau v√† quy·∫øt ƒë·ªãnh c√≥ c·∫ßn t√¨m ki·∫øm th√¥ng tin t·ª´ knowledge base kh√¥ng:
                
                C√¢u h·ªèi: "{message_content}"
                
                Tr·∫£ l·ªùi ch·ªâ "YES" ho·∫∑c "NO".
                """

				decision_response = await self.llm.ainvoke([HumanMessage(content=decision_prompt)])
				needs_rag = 'YES' in decision_response.content.upper()

			logger.info(f'RAG analysis for "{message_content[:50]}...": {needs_rag}')
			return needs_rag

		except Exception as e:
			logger.error(f'Error analyzing message for RAG: {str(e)}')
			return True  # Default to using RAG on error

	async def process_message(
		self,
		user_message: str,
		user_id: Optional[str] = None,
		conversation_id: Optional[str] = None,
		config_override: Optional[Dict[str, Any]] = None,
	) -> Dict[str, Any]:
		"""Process message v·ªõi enhanced dual RAG"""
		start_time = time.time()
		session_id = conversation_id or f'session_{int(time.time())}'

		logger.workflow_start(
			'Enhanced Dual RAG Message Processing',
			user_id=user_id,
			conversation_id=conversation_id,
			message_length=len(user_message),
		)

		try:
			# Create initial state
			initial_state = StateManager.create_initial_state(user_message=user_message, user_id=user_id, session_id=session_id)

			# Add conversation_id to metadata
			if conversation_id:
				initial_state['conversation_metadata']['conversation_id'] = conversation_id

			# Prepare config
			runtime_config = {
				'configurable': {
					'thread_id': session_id,
					**self.config.to_dict(),
				}
			}

			if config_override:
				runtime_config['configurable'].update(config_override)

			# Execute workflow
			final_state = await self.compiled_graph.ainvoke(initial_state, config=runtime_config)

			# Extract response
			response = self._extract_response(final_state)
			processing_time = time.time() - start_time

			logger.success(
				'Enhanced Dual RAG processing completed',
				processing_time=processing_time,
				response_length=len(response),
				dual_rag_used=bool(final_state.get('combined_rag_context')),
			)

			return {
				'response': response,
				'state': final_state,
				'metadata': {
					'processing_time': processing_time,
					'dual_rag_used': bool(final_state.get('combined_rag_context')),
					'routing_decision': final_state.get('dual_rag_routing'),
					'global_sources': len(final_state.get('global_rag_context', [])),
					'conversation_sources': len(final_state.get('conversation_rag_context', [])),
					'workflow_type': 'enhanced_dual_rag',
				},
			}

		except Exception as e:
			logger.error(f'Error in enhanced dual RAG processing: {str(e)}')
			return {
				'response': f'Xin l·ªói, c√≥ l·ªói x·∫£y ra trong qu√° tr√¨nh x·ª≠ l√Ω: {str(e)}',
				'state': {},
				'metadata': {
					'processing_time': time.time() - start_time,
					'error': str(e),
					'workflow_type': 'enhanced_dual_rag',
				},
			}

	def _extract_response(self, final_state: Dict[str, Any]) -> str:
		"""Extract response t·ª´ final state"""
		messages = final_state.get('messages', [])
		if messages:
			last_message = messages[-1]
			return last_message.content if hasattr(last_message, 'content') else str(last_message)
		return 'Kh√¥ng c√≥ ph·∫£n h·ªìi ƒë∆∞·ª£c t·∫°o.'

	async def initialize_global_knowledge(self) -> Dict[str, Any]:
		"""Initialize Global Knowledge Base"""
		if not self.global_kb_service:
			return {'error': 'Global KB Service not available'}

		try:
			result = await self.global_kb_service.initialize_default_knowledge()
			logger.info('Global Knowledge Base initialized successfully')
			return result
		except Exception as e:
			logger.error(f'Error initializing global knowledge: {str(e)}')
			return {'error': str(e)}


def create_enhanced_dual_rag_workflow(db_session: Session, config: Optional[WorkflowConfig] = None) -> EnhancedDualRAGWorkflow:
	"""Factory function ƒë·ªÉ t·∫°o enhanced dual RAG workflow"""
	return EnhancedDualRAGWorkflow(db_session, config)
