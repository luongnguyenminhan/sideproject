"""
Simplified Chat Workflow
Router â†’ RAG Query (Always Dual) â†’ Agent â†’ Tools â†’ Response Generator
"""

import asyncio
import time
import json
import logging
from datetime import datetime, timezone
from typing import Dict, Any, Optional, List, Literal, Union

from dotenv import load_dotenv
from pydantic import BaseModel, Field
from sqlalchemy.orm import Session

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import AIMessage, SystemMessage
from langgraph.graph import StateGraph, END, START
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.memory import MemorySaver

from .state.workflow_state import AgentState, StateManager
from .config.workflow_config import WorkflowConfig
from .tools.basic_tools import get_tools, get_tool_definitions
from .utils.color_logger import get_color_logger
from .guardrails.manager import ChatWorkflowGuardrailManager

load_dotenv()

# Initialize colorful logger
logger = get_color_logger(__name__)


# Router Schema
class RouterDecision(BaseModel):
	"""Router decision schema for query routing."""

	target: Literal['rag_query', 'agent'] = Field(description='Target node Ä‘á»ƒ route query Ä‘áº¿n')
	explanation: str = Field(description='Explanation cho quyáº¿t Ä‘á»‹nh routing')


# System Prompts
DEFAULT_SYSTEM_PROMPT = """
Báº¡n lÃ  Enterview AI Assistant - Trá»£ lÃ½ thÃ´ng minh cá»§a Enterview, cÃ´ng cá»¥ AI há»— trá»£ ngÆ°á»i dÃ¹ng khÃ¡m phÃ¡ báº£n thÃ¢n vÃ  trong viá»‡c tÃ¬m kiáº¿m viá»‡c lÃ m.
   Báº¡n cÃ³ thá»ƒ tráº£ lá»i cÃ¡c cÃ¢u há»i vá» báº£n thÃ¢n, tÃ¬m kiáº¿m viá»‡c lÃ m, vÃ  cÃ¡c váº¥n Ä‘á» liÃªn quan Ä‘áº¿n viá»‡c lÃ m vá»›i giá»ng Ä‘iá»‡u thÃ¢n thiá»‡n vÃ  chuyÃªn nghiá»‡p.
   
   Sá»¨ Má»†NH Cá»¦A ENTERVIEW:
   - GiÃºp ngÆ°á»i dÃ¹ng tÃ¬m hiá»ƒu báº£n thÃ¢n vÃ  khÃ¡m phÃ¡ nhá»¯ng gÃ¬ há» thá»±c sá»± muá»‘n.
   - Cung cáº¥p thÃ´ng tin vá» cÃ¡c cÃ´ng ty vÃ  vá»‹ trÃ­ phÃ¹ há»£p vá»›i nhu cáº§u cá»§a ngÆ°á»i dÃ¹ng.
   - Há»— trá»£ trong viá»‡c tÃ¬m kiáº¿m viá»‡c lÃ m vÃ  phÃ¡t triá»ƒn sá»± nghiá»‡p.
   
   TÃNH NÄ‚NG CHÃNH:
   - TÃ¬m hiá»ƒu báº£n thÃ¢n vÃ  nhu cáº§u viá»‡c lÃ m cá»§a ngÆ°á»i dÃ¹ng.
   - Cung cáº¥p thÃ´ng tin vá» cÃ¡c cÃ´ng ty vÃ  vá»‹ trÃ­ phÃ¹ há»£p vá»›i nhu cáº§u viá»‡c lÃ m cá»§a ngÆ°á»i dÃ¹ng.
   - Há»— trá»£ trong viá»‡c tÃ¬m kiáº¿m viá»‡c lÃ m vÃ  phÃ¡t triá»ƒn sá»± nghiá»‡p.
   
   LÆ¯U Ã:
   - Tá»« chá»‘i tráº£ lá»i cÃ¡c cÃ¢u há»i khÃ´ng liÃªn quan Ä‘áº¿n viá»‡c lÃ m.
   - Tráº£ lá»i cÃ¡c cÃ¢u há»i má»™t cÃ¡ch chuyÃªn nghiá»‡p vÃ  thÃ¢n thiá»‡n.
   HÃ£y tráº£ lá»i vá»›i tinh tháº§n nhiá»‡t tÃ¬nh vÃ  chuyÃªn nghiá»‡p cá»§a Enterview AI Assistant, luÃ´n sáºµn sÃ ng há»— trá»£ vÃ  khuyáº¿n khÃ­ch má»i ngÆ°á»i tham gia vÃ o cÃ¡c hoáº¡t Ä‘á»™ng Ã½ nghÄ©a cá»§a Enterview!
"""
ROUTER_SYSTEM_PROMPT = """
ðŸ§­ Báº¡n lÃ  Router Agent thÃ´ng minh cho há»‡ thá»‘ng Enterview AI Assistant. PhÃ¢n tÃ­ch user query vÃ  quyáº¿t Ä‘á»‹nh route phÃ¹ há»£p nháº¥t.

ðŸŽ¯ TARGET NODES AVAILABLE:
1. "rag_query" - Cho cÃ¢u há»i liÃªn quan Ä‘áº¿n kiáº¿n thá»©c, thÃ´ng tin cáº§n truy xuáº¥t tá»« knowledge base
2. "agent" - Cho cÃ¡c cÃ¢u há»i trÃ² chuyá»‡n thÃ´ng thÆ°á»ng, toÃ¡n há»c Ä‘Æ¡n giáº£n

ðŸ“‹ QUY Táº®C ROUTING:
- Náº¿u cÃ¢u há»i liÃªn quan Ä‘áº¿n kiáº¿n thá»©c, thÃ´ng tin, hoáº¡t Ä‘á»™ng, dá»± Ã¡n, lá»‹ch sá»­: chá»n "rag_query"
- Náº¿u lÃ  cÃ¢u há»i trÃ² chuyá»‡n thÃ´ng thÆ°á»ng, tÃ­nh toÃ¡n Ä‘Æ¡n giáº£n: chá»n "agent"

âš ï¸ LÆ¯U Ã: Æ¯u tiÃªn "rag_query" cho háº§u háº¿t cÃ¢u há»i vá» thÃ´ng tin.
"""


class Workflow:
	"""Simplified Chat Workflow: Router â†’ RAG Query (Always Dual) â†’ Agent â†’ Tools â†’ Response Generator"""

	def __init__(self, db_session: Session, config: Optional[WorkflowConfig] = None):
		"""Initialize simplified workflow"""
		self.start_time = time.time()
		logger.workflow_start(
			'Simplified Workflow Initialization',
			db_session_type=type(db_session).__name__,
			config_provided=config is not None,
		)

		self.db_session = db_session
		self.config = config or WorkflowConfig.from_env()
		self.config.db_session = db_session

		# Initialize LLM
		self.llm = ChatGoogleGenerativeAI(model=self.config.model_name, temperature=self.config.temperature)

		# Initialize services
		self._init_global_kb_service()
		self._init_guardrails()

		# Build workflow
		self.compiled_graph = self._build_workflow()

		logger.success(
			'ðŸš€ Simplified Workflow initialized successfully',
			initialization_time=time.time() - self.start_time,
		)

	def _init_global_kb_service(self):
		"""Initialize Global Knowledge Base Service"""
		try:
			from app.modules.agentic_rag.services.global_kb_service import (
				GlobalKBService,
			)

			self.global_kb_service = GlobalKBService(self.db_session)
			logger.info('Global KB Service initialized successfully')
		except Exception as e:
			logger.error(f'Error initializing Global KB Service: {str(e)}')
			self.global_kb_service = None

	def _init_guardrails(self):
		"""Initialize Guardrail System"""
		try:
			guardrail_config = {
				'enable_input_guardrails': True,
				'enable_output_guardrails': True,
				'max_input_length': 5000,
				'strict_mode': False,
			}
			self.guardrail_manager = ChatWorkflowGuardrailManager(guardrail_config)
			logger.info('Guardrail system initialized successfully')
		except Exception as e:
			logger.error(f'Error initializing guardrails: {str(e)}')
			self.guardrail_manager = None

	def _build_workflow(self) -> StateGraph:
		"""Build simplified workflow vá»›i dual RAG máº·c Ä‘á»‹nh"""
		workflow = StateGraph(AgentState)

		# Get tools
		tools = get_tools(self.config)
		tool_node = ToolNode(tools)

		# Create wrapper functions for nodes
		async def router_wrapper(state, config=None):
			return await self._router_node(state, config or {})

		async def rag_query_wrapper(state, config=None):
			return await self._rag_query_node(state, config or {})

		async def agent_wrapper(state, config=None):
			return await self._agent_node(state, config or {})

		async def response_wrapper(state, config=None):
			return await self._response_generator_node(state, config or {})

		def route_wrapper(state):
			return self._route_decision(state)

		def should_continue_wrapper(state):
			return self._should_continue(state)

		# Add simplified nodes
		workflow.add_node('router', router_wrapper)
		workflow.add_node('rag_query', rag_query_wrapper)
		workflow.add_node('agent', agent_wrapper)
		workflow.add_node('tools', tool_node)
		workflow.add_node('response_generator', response_wrapper)

		# Set entry point
		workflow.set_entry_point('router')

		# Simplified routing: router â†’ (rag_query | agent)
		workflow.add_conditional_edges(
			'router',
			route_wrapper,
			{
				'rag_query': 'rag_query',
				'agent': 'agent',
			},
		)

		# Simple flow: rag_query â†’ response_generator
		workflow.add_edge('rag_query', 'response_generator')

		# Agent flow: agent â†’ (tools | END)
		workflow.add_conditional_edges('agent', should_continue_wrapper, {'tools': 'tools', END: END})
		workflow.add_edge('tools', 'agent')

		# Response generator â†’ END
		workflow.add_edge('response_generator', END)

		# Compile with memory
		checkpointer = MemorySaver()
		return workflow.compile(checkpointer=checkpointer)

	async def _router_node(self, state: AgentState, config: Dict[str, Any]) -> AgentState:
		"""Router Node vá»›i Intelligent routing + Guardrails"""
		start_time = time.time()
		thread_id = config.get('configurable', {}).get('thread_id', 'unknown')

		logger.workflow_start(
			'Router Node - Intelligent Query Routing with Guardrails',
			thread_id=thread_id,
			router_enabled=True,
			guardrails_enabled=True,
		)

		# Get user message
		messages = state.get('messages', [])
		if not messages:
			return {
				**state,
				'router_decision': {
					'target': 'general',
					'explanation': 'No user input',
				},
			}

		# Extract user query
		user_query = None
		for msg in reversed(messages):
			if hasattr(msg, 'content') and msg.content:
				user_query = msg.content
				break

		if not user_query:
			return {
				**state,
				'router_decision': {'target': 'general', 'explanation': 'Empty query'},
			}

		# Apply guardrails
		if self.guardrail_manager:
			try:
				guardrail_context = {
					'thread_id': thread_id,
					'user_id': config.get('configurable', {}).get('user_id', 'unknown'),
					'conversation_step': 'router_input',
				}

				guardrail_result = self.guardrail_manager.check_user_input(user_query, guardrail_context)

				if not guardrail_result.passed:
					logger.error('Input BLOCKED by guardrails')
					return {
						**state,
						'router_decision': {
							'target': 'general',
							'explanation': 'Input blocked by content safety guardrails',
						},
						'guardrail_blocked': True,
					}

				if guardrail_result.modified_content:
					user_query = guardrail_result.modified_content

			except Exception as e:
				logger.error(f'Guardrail check failed: {str(e)}')

		# Route decision using LLM
		try:
			router_prompt = ChatPromptTemplate.from_messages([
				('system', ROUTER_SYSTEM_PROMPT),
				(
					'human',
					'User query: {input}\n\nAnalyze and determine the best routing target.',
				),
			])

			router_chain = router_prompt | self.llm.with_structured_output(RouterDecision)
			router_result = await router_chain.ainvoke({'input': user_query})

			target = router_result.target if hasattr(router_result, 'target') else 'general'
			explanation = router_result.explanation if hasattr(router_result, 'explanation') else 'Default routing'

			logger.info(f'ðŸŽ¯ Router Decision: {target} - {explanation}')

			processing_time = time.time() - start_time
			logger.info(
				'Router Node - Intelligent Query Routing with Guardrails',
				processing_time,
				target_selected=target,
			)

			return {
				**state,
				'router_decision': {'target': target, 'explanation': explanation},
				'routing_complete': True,
			}

		except Exception as e:
			logger.error(f'Router failed: {str(e)}')
			return {
				**state,
				'router_decision': {
					'target': 'general',
					'explanation': f'Router error: {str(e)[:100]}',
				},
				'routing_complete': True,
			}

	async def _rag_query_node(self, state: AgentState, config: Dict[str, Any]) -> AgentState:
		"""RAG Query Node - Always use Dual RAG (Global KB + Conversation KB)"""
		start_time = time.time()
		thread_id = config.get('configurable', {}).get('thread_id', 'unknown')

		logger.workflow_start('RAG Query Node - Dual RAG Retrieval', thread_id=thread_id)

		messages = state.get('messages', [])
		if not messages:
			return state

		# Get user query
		user_query = None
		for msg in reversed(messages):
			if hasattr(msg, 'content') and msg.content:
				user_query = msg.content
				break

		if not user_query:
			return state

		try:
			# Always use dual RAG approach
			conv_context = ''
			global_context = ''

			# 1. Search Conversation KB
			try:
				collection_id = f'conversation_{thread_id}'
				logger.info(f'ðŸ” Searching conversation KB: {collection_id}')

				from app.modules.agentic_rag.agent.rag_graph import RAGAgentGraph
				from app.modules.agentic_rag.repository.kb_repo import KBRepository

				kb_repo = KBRepository(collection_name=collection_id)
				rag_agent = RAGAgentGraph(kb_repo=kb_repo, collection_id=collection_id)
				conv_result = await rag_agent.answer_query(query=user_query, collection_id=collection_id)

				conv_answer = conv_result.get('answer', '')
				conv_sources = conv_result.get('sources', [])

				if conv_answer:
					conv_context = f'ðŸ“ Conversation Knowledge:\n{conv_answer}'
					if conv_sources:
						conv_context += '\nðŸ“š Sources:'
						for i, source in enumerate(conv_sources, 1):
							source_info = f'\n{i}. Document ID: {source.get("id", "Unknown")}'
							if 'metadata' in source and 'source' in source['metadata']:
								source_info += f' (File: {source["metadata"]["source"]})'
							conv_context += source_info

			except Exception as e:
				logger.warning(f'Conversation KB search failed: {str(e)}')

			# 2. Search Global KB
			if self.global_kb_service:
				try:
					logger.info('ðŸŒ Searching global KB')
					global_results = await self.global_kb_service.search_global_knowledge(user_query, top_k=3)
					logger.debug(f'[DEBUG] Global KB search results: {global_results}')
					if global_results:
						# Combine top results into a single context string
						contexts = []
						for i, item in enumerate(global_results, 1):
							content = item.get('content', '')
							title = item.get('metadata', {}).get('title', '')
							source = item.get('metadata', {}).get('source', '')
							if title or source:
								contexts.append(f'{i}. {title}\n{content}\n(Source: {source})')
							else:
								contexts.append(f'{i}. {content}')
						global_context = 'ðŸŒ Global Knowledge:\n' + '\n\n'.join(contexts)
				except Exception as e:
					logger.warning(f'Global KB search failed: {str(e)}')

			# 3. Combine both contexts
			combined_context = ''
			if conv_context and global_context:
				combined_context = f'{conv_context}\n\n{global_context}'
			elif conv_context:
				combined_context = conv_context
			elif global_context:
				combined_context = global_context

			processing_time = time.time() - start_time
			logger.info(
				'RAG Query Node - Dual RAG Retrieval',
				processing_time,
				context_retrieved=bool(combined_context),
				conv_context_found=bool(conv_context),
				global_context_found=bool(global_context),
			)

			return {
				**state,
				'combined_rag_context': combined_context,
				'rag_used': True,
				'retrieval_quality': 'good' if combined_context else 'no_results',
			}

		except Exception as e:
			logger.error(f'Dual RAG Query failed: {str(e)}')
			return {
				**state,
				'combined_rag_context': '',
				'rag_used': False,
				'retrieval_quality': 'error',
			}

	async def _agent_node(self, state: AgentState, config: Dict[str, Any]) -> AgentState:
		"""Main Agent Node vá»›i RAG context vÃ  tools"""
		start_time = time.time()
		thread_id = config.get('configurable', {}).get('thread_id', 'unknown')

		logger.workflow_start(
			'Agent Node - Model Invocation with Context and Tools',
			thread_id=thread_id,
			has_context=bool(state.get('combined_rag_context')),
		)

		# Get system prompt with persona support
		system_prompt = DEFAULT_SYSTEM_PROMPT
		if self.config and self.config.persona_enabled:
			persona_prompt = self.config.get_persona_prompt()
			if persona_prompt:
				system_prompt = persona_prompt

		# Build enhanced system prompt
		persona_info = ''
		if self.config and self.config.persona_enabled:
			persona_info = f"""
ðŸŽ­ PERSONA ACTIVE: {self.config.get_persona_name()}
Persona Type: {self.config.persona_type.value if self.config.persona_type else 'none'}
"""

		enhanced_system = f"""{system_prompt}

ðŸ¤– SIMPLIFIED WORKFLOW AI:{persona_info}

ðŸ› ï¸ AVAILABLE TOOLS:
- add(a, b): Cá»™ng hai sá»‘
- subtract(a, b): Trá»« hai sá»‘  
- multiply(a, b): NhÃ¢n hai sá»‘
- divide(a, b): Chia hai sá»‘

ðŸ“Š CONTEXT: {thread_id}
ðŸ“ˆ RAG Status: {state.get('retrieval_quality', 'unknown')}
ðŸ”¥ Features: Router + Dual RAG + Guardrails + Tools

ðŸŒŸ HÆ¯á»šNG DáºªN:
1. ðŸ“š Sá»­ dá»¥ng dual RAG context Ä‘Æ°á»£c cung cáº¥p lÃ m nguá»“n chÃ­nh
2. ðŸ§® Sá»­ dá»¥ng math tools khi cáº§n tÃ­nh toÃ¡n
3. ðŸ’¡ Káº¿t há»£p kiáº¿n thá»©c Ä‘á»ƒ tráº£ lá»i toÃ n diá»‡n
4. ðŸŽ¯ Tráº£ lá»i tá»± nhiÃªn, khÃ´ng ghi nguá»“n context
5. ðŸ—£ï¸ Giá»¯ tinh tháº§n CGSEM nhiá»‡t huyáº¿t vÃ  sÃ¡ng táº¡o
"""

		# Add dual RAG context if available
		combined_context = state.get('combined_rag_context')
		if combined_context:
			enhanced_system += f'\n\nðŸ”— DUAL RAG KNOWLEDGE BASE:\n{combined_context}'

		# Prepare messages
		messages = state.get('messages', [])
		if not messages:
			return {'messages': [SystemMessage(content=enhanced_system)]}

		# Create prompt
		prompt = ChatPromptTemplate.from_messages([
			('system', enhanced_system),
			MessagesPlaceholder(variable_name='chat_history'),
			MessagesPlaceholder(variable_name='agent_scratchpad'),
		])

		formatted_prompt = prompt.format_messages(
			chat_history=messages,
			agent_scratchpad=[],
		)

		# Invoke model with tools
		tool_definitions = get_tool_definitions(self.config)
		model_with_tools = self.llm.bind_tools(tool_definitions)

		response = await model_with_tools.ainvoke(
			formatted_prompt,
			{
				'system_time': datetime.now(tz=timezone.utc).isoformat(),
				'unified_mode': True,
				'conversation_id': thread_id,
			},
		)

		processing_time = time.time() - start_time
		logger.info(
			'Agent Node - Model Invocation',
			processing_time,
			response_length=len(str(response.content)),
		)

		return {**state, 'messages': messages + [response]}

	async def _response_generator_node(self, state: AgentState, config: Dict[str, Any]) -> AgentState:
		"""Generate final response vá»›i RAG context"""
		logger.info('ðŸ“ Response generator executing...')

		try:
			messages = state.get('messages', [])
			combined_context = state.get('combined_rag_context', '')

			# Build enhanced prompt
			if combined_context:
				system_prompt = f"""Báº¡n lÃ  AI assistant thÃ´ng minh vá»›i kháº£ nÄƒng truy cáº­p kiáº¿n thá»©c tá»« nhiá»u nguá»“n.

CONTEXT Tá»ª KNOWLEDGE BASES:
{combined_context}

HÆ¯á»šNG DáºªN:
- Sá»­ dá»¥ng thÃ´ng tin tá»« context Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i
- Náº¿u context khÃ´ng Ä‘á»§, hÃ£y thá»«a nháº­n vÃ  Ä‘Æ°a ra cÃ¢u tráº£ lá»i tá»‘t nháº¥t cÃ³ thá»ƒ
- LuÃ´n cung cáº¥p thÃ´ng tin chÃ­nh xÃ¡c vÃ  há»¯u Ã­ch
- Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t trá»« khi Ä‘Æ°á»£c yÃªu cáº§u khÃ¡c
- Ghi rÃµ nguá»“n thÃ´ng tin khi cáº§n thiáº¿t
"""
			else:
				system_prompt = DEFAULT_SYSTEM_PROMPT

			# Generate response
			enhanced_messages = [SystemMessage(content=system_prompt)] + messages
			response = await self.llm.ainvoke(enhanced_messages)

			# Add metadata
			routing_info = state.get('rag_routing', {})
			if routing_info:
				metadata_note = f'\n\n_[Sá»­ dá»¥ng {routing_info} knowledge base(s)]_'
				response.content += metadata_note

			return {
				**state,
				'messages': messages + [response],
				'current_node': 'response_generator',
			}

		except Exception as e:
			logger.error(f'Response generator error: {str(e)}')
			error_response = AIMessage(content=f'Xin lá»—i, cÃ³ lá»—i trong quÃ¡ trÃ¬nh táº¡o pháº£n há»“i: {str(e)}')
			return {**state, 'messages': state.get('messages', []) + [error_response]}

	def _route_decision(self, state: AgentState) -> str:
		"""Simplified route decision logic"""
		router_decision = state.get('router_decision', {})
		target = router_decision.get('target', 'agent') if isinstance(router_decision, dict) else 'agent'

		# Simple mapping
		if target == 'rag_query':
			actual_target = 'rag_query'
		else:
			actual_target = 'agent'

		logger.info(f'ðŸ”€ Routing: {target} â†’ {actual_target}')
		return actual_target

	def _should_continue(self, state: AgentState) -> str:
		"""Determine if agent should continue with tools or end"""
		messages = state.get('messages', [])
		if not messages:
			return END

		last_message = messages[-1]
		if not hasattr(last_message, 'tool_calls') or not last_message.tool_calls:
			return END
		else:
			return 'tools'

	async def process_message(
		self,
		user_message: str,
		user_id: Optional[str] = None,
		conversation_id: Optional[str] = None,
		config_override: Optional[Dict[str, Any]] = None,
	) -> Dict[str, Any]:
		"""Process message vá»›i unified workflow"""
		start_time = time.time()
		session_id = conversation_id or f'session_{int(time.time())}'

		logger.workflow_start(
			'Simplified Workflow Message Processing',
			user_id=user_id,
			conversation_id=conversation_id,
			message_length=len(user_message),
		)

		try:
			# Create initial state
			initial_state = StateManager.create_initial_state(user_message=user_message, user_id=user_id, session_id=session_id)

			# Add conversation_id to metadata
			if conversation_id:
				initial_state['conversation_metadata']['conversation_id'] = conversation_id

			# Prepare config
			runtime_config = {
				'configurable': {
					'thread_id': session_id,
					**self.config.to_dict(),
				}
			}

			if config_override:
				runtime_config['configurable'].update(config_override)

			# Execute workflow
			final_state = await self.compiled_graph.ainvoke(initial_state, config=runtime_config)

			# Extract response
			response = self._extract_response(final_state)
			processing_time = time.time() - start_time

			logger.success(
				'Simplified Workflow processing completed',
				processing_time=processing_time,
				response_length=len(response),
				features_used={
					'router': final_state.get('routing_complete', False),
					'rag': bool(final_state.get('combined_rag_context')),
					'guardrails': not final_state.get('guardrail_blocked', False),
				},
			)

			return {
				'response': response,
				'state': final_state,
				'metadata': {
					'processing_time': processing_time,
					'workflow_type': 'simplified',
					'router_decision': final_state.get('router_decision'),
					'rag_used': bool(final_state.get('combined_rag_context')),
					'guardrails_passed': not final_state.get('guardrail_blocked', False),
				},
			}

		except Exception as e:
			logger.error(f'Simplified workflow error: {str(e)}')
			return {
				'response': f'Xin lá»—i, cÃ³ lá»—i xáº£y ra trong quÃ¡ trÃ¬nh xá»­ lÃ½: {str(e)}',
				'state': {},
				'metadata': {
					'processing_time': time.time() - start_time,
					'error': str(e),
					'workflow_type': 'simplified',
				},
			}

	def _extract_response(self, final_state: Dict[str, Any]) -> str:
		"""Extract response from final state"""
		messages = final_state.get('messages', [])
		if messages:
			last_message = messages[-1]
			return last_message.content if hasattr(last_message, 'content') else str(last_message)
		return 'KhÃ´ng cÃ³ pháº£n há»“i Ä‘Æ°á»£c táº¡o.'

	async def initialize_global_knowledge(self) -> Dict[str, Any]:
		"""Initialize Global Knowledge Base"""
		if not self.global_kb_service:
			return {'error': 'Global KB Service not available'}

		try:
			result = await self.global_kb_service.initialize_default_knowledge()
			logger.info('Global Knowledge Base initialized successfully')
			return result
		except Exception as e:
			logger.error(f'Error initializing global knowledge: {str(e)}')
			return {'error': str(e)}


# Factory functions
def create_workflow(db_session: Session, config: Optional[WorkflowConfig] = None) -> Workflow:
	"""Factory function Ä‘á»ƒ táº¡o simplified workflow"""
	return Workflow(db_session, config)


# Backward compatibility aliases
def create_unified_workflow(db_session: Session, config: Optional[WorkflowConfig] = None) -> Workflow:
	"""Alias for create_workflow - backward compatibility"""
	return create_workflow(db_session, config)


def create_agentic_rag_workflow(db_session: Session, config: Optional[WorkflowConfig] = None) -> Workflow:
	"""Alias for create_workflow - backward compatibility"""
	return create_workflow(db_session, config)


def create_enhanced_rag_workflow(db_session: Session, config: Optional[WorkflowConfig] = None) -> Workflow:
	"""Alias for create_workflow - backward compatibility"""
	return create_workflow(db_session, config)


def create_workflow_with_rag(db_session: Session, config: Optional[WorkflowConfig] = None) -> Workflow:
	"""Alias for create_workflow - backward compatibility"""
	return create_workflow(db_session, config)
