"""
Basic Chat Workflow with integrated Agentic RAG functionality
Advanced workflow with query analysis, routing, and self-correction using Agentic RAG KBRepository
"""

from datetime import datetime, timezone
import time
from dotenv import load_dotenv
from langchain_core.messages import SystemMessage
from langchain_core.tools import BaseTool
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.errors import NodeInterrupt
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langgraph.checkpoint.memory import MemorySaver

from .tools.basic_tools import tools
from .state.workflow_state import AgentState
from .config.workflow_config import WorkflowConfig
from .utils.color_logger import get_color_logger, Colors

load_dotenv()

# Initialize colorful logger
color_logger = get_color_logger(__name__)

# Default system prompt for the financial assistant
DEFAULT_SYSTEM_PROMPT = """
B·∫°n l√† tr·ª£ l√Ω t√†i ch√≠nh th√¥ng minh MoneyEZ v·ªõi kh·∫£ nƒÉng RAG (Retrieval-Augmented Generation), m·ªôt tr·ª£ l√Ω AI ƒë∆∞·ª£c t·∫°o ra ƒë·ªÉ gi√∫p ng∆∞·ªùi d√πng qu·∫£n l√Ω t√†i ch√≠nh c√° nh√¢n.

Nhi·ªám v·ª• c·ªßa b·∫°n:
1. Gi√∫p ng∆∞·ªùi d√πng theo d√µi chi ti√™u h√†ng ng√†y
2. Ph√¢n lo·∫°i c√°c kho·∫£n chi ti√™u v√†o c√°c danh m·ª•c ph√π h·ª£p
3. Cung c·∫•p th√¥ng tin v√† t∆∞ v·∫•n t√†i ch√≠nh t·ª´ knowledge base
4. Tr·∫£ l·ªùi m·ªçi c√¢u h·ªèi li√™n quan ƒë·∫øn t√†i ch√≠nh c√° nh√¢n m·ªôt c√°ch ch√≠nh x√°c v√† h·ªØu √≠ch
5. Th·ª±c hi·ªán c√°c ph√©p t√≠nh c∆° b·∫£n khi c·∫ßn thi·∫øt
6. S·ª≠ d·ª•ng ki·∫øn th·ª©c t·ª´ t√†i li·ªáu ƒë√£ upload ƒë·ªÉ t∆∞ v·∫•n chuy√™n nghi·ªáp

C√¥ng c·ª• c√≥ s·∫µn:
- Ph√©p t√≠nh: add, subtract, multiply, divide
- RAG: answer_query_collection - Tr·∫£ l·ªùi c√¢u h·ªèi t·ª´ knowledge base c·ªßa conversation c·ª• th·ªÉ
- Search: search_knowledge_base - T√¨m ki·∫øm th√¥ng tin trong knowledge base

H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng RAG:
- Khi ƒë∆∞·ª£c h·ªèi v·ªÅ th√¥ng tin c·ª• th·ªÉ, h√£y s·ª≠ d·ª•ng answer_query_collection v·ªõi conversation_id
- S·ª≠ d·ª•ng search_knowledge_base ƒë·ªÉ t√¨m ki·∫øm th√¥ng tin tr∆∞·ªõc khi tr·∫£ l·ªùi
- Lu√¥n ∆∞u ti√™n th√¥ng tin t·ª´ knowledge base khi c√≥

B·∫°n lu√¥n ph√¢n t√≠ch query v√† s·ª≠ d·ª•ng c√¥ng c·ª• ph√π h·ª£p nh·∫•t ƒë·ªÉ tr·∫£ l·ªùi.
"""

# Initialize the default model
model = ChatGoogleGenerativeAI(model='gemini-2.0-flash-lite', temperature=0)

# Global workflow config
workflow_config = None


def initialize_services(db_session, config=None):
	"""Initialize workflow configuration for Agentic RAG"""
	global workflow_config

	color_logger.workflow_start(
		'Agentic RAG Workflow Configuration',
		db_session_id=id(db_session),
		config_provided=config is not None,
	)

	try:
		workflow_config = config or WorkflowConfig.from_env()
		color_logger.info(
			f'üìã {Colors.BOLD}CONFIG:{Colors.RESET}{Colors.CYAN} Agentic RAG workflow configured',
			Colors.CYAN,
			model_name=workflow_config.model_name,
			collection_name=workflow_config.collection_name,
		)

		color_logger.workflow_complete(
			'Agentic RAG Workflow Configuration',
			time.time(),
			services_count=1,
			status='success',
		)
		return True
	except Exception as e:
		color_logger.error(
			f'Failed to initialize Agentic RAG workflow config: {str(e)}',
			error_type=type(e).__name__,
			traceback_available=True,
		)
		return False


def should_continue(state):
	"""Determine if the agent should continue with tool execution or end."""
	messages = state.get('messages', [])
	if not messages:
		return END

	last_message = messages[-1]
	if not hasattr(last_message, 'tool_calls') or not last_message.tool_calls:
		return END
	else:
		return 'tools'


def get_tool_defs(config):
	"""Get tool definitions for binding to the model."""
	from .tools.basic_tools import get_tool_definitions

	return get_tool_definitions(config)


def get_tools(config):
	"""Get tool instances for the tool node."""
	from .tools.basic_tools import get_tools as get_basic_tools

	return get_basic_tools(config)


async def call_model(state, config):
	"""Agentic RAG - Enhanced Model Call with RAG Tools (File Indexing Service)"""
	start_time = time.time()
	thread_id = config.get('configurable', {}).get('thread_id', 'unknown')

	color_logger.workflow_start(
		'Agentic RAG - Model Invocation with RAG Tools (File Indexing)',
		thread_id=thread_id,
		has_context=bool(state.get('rag_context')),
		agentic_rag_enabled=True,
		rag_tools_enabled=True,
	)

	# Get system prompt
	system = config.get('configurable', {}).get('system_prompt', DEFAULT_SYSTEM_PROMPT)

	# Enhanced system prompt for Agentic RAG with Tools
	agentic_system = f"""{system}

ü§ñ B·∫†N L√Ä AGENTIC RAG AI v·ªõi RAG TOOLS - S·ª≠ d·ª•ng c√¥ng c·ª• m·ªôt c√°ch th√¥ng minh:

RAG Tools Available:
- answer_query_collection(query, conversation_id): Tr·∫£ l·ªùi c√¢u h·ªèi t·ª´ knowledge base
- search_knowledge_base(query, collection_id, top_k): T√¨m ki·∫øm trong knowledge base
- Basic math tools: add, subtract, multiply, divide

Conversation Context: {thread_id}
Retrieval Strategy: {state.get('retrieval_strategy_used', 'comprehensive')}
Document Quality: {state.get('retrieval_quality', 'unknown')}
Grading Score: {state.get('grading_score', 0):.2f}
Agentic RAG: {state.get('agentic_rag_used', True)}

H∆∞·ªõng d·∫´n ƒë·∫∑c bi·ªát:
1. üìö KHI C·∫¶N TH√îNG TIN: S·ª≠ d·ª•ng answer_query_collection v·ªõi conversation_id = "{thread_id}"
2. üîç KHI C·∫¶N T√åM KI·∫æM: S·ª≠ d·ª•ng search_knowledge_base tr∆∞·ªõc
3. üßÆ KHI C·∫¶N T√çNH TO√ÅN: S·ª≠ d·ª•ng math tools
4. üí° K·∫øt h·ª£p th√¥ng tin t·ª´ tools v·ªõi ki·∫øn th·ª©c c·ªßa b·∫°n
5. üìù Lu√¥n cite sources khi s·ª≠ d·ª•ng th√¥ng tin t·ª´ RAG tools
"""

	# Add RAG context if available (from file indexing service)
	rag_context = state.get('rag_context')
	if rag_context:
		context_quality = state.get('retrieval_quality', 'unknown')
		context_length = sum(len(ctx) for ctx in rag_context)

		color_logger.info(
			f'üß† {Colors.BOLD}AGENTIC RAG CONTEXT + RAG TOOLS:{Colors.RESET}{Colors.BRIGHT_YELLOW} Quality={context_quality}',
			Colors.BRIGHT_YELLOW,
			sources_count=len(rag_context),
			total_context_length=context_length,
			quality=context_quality,
			rag_tools_enabled=True,
		)

		enhanced_system = f'{agentic_system}\n\nüîó KI·∫æN TH·ª®C T·ª™ AGENTIC RAG (Quality: {context_quality}):\n' + '\n'.join(rag_context)
	else:
		color_logger.info(
			f'üìù {Colors.BOLD}RAG TOOLS ONLY:{Colors.RESET}{Colors.DIM} Using tools for knowledge access',
			Colors.DIM,
			rag_tools_enabled=True,
		)
		enhanced_system = agentic_system

	# Prepare messages
	messages = state.get('messages', [])
	if not messages:
		return {'messages': [SystemMessage(content=enhanced_system)]}

	# Create enhanced prompt
	prompt = ChatPromptTemplate.from_messages([
		('system', enhanced_system),
		MessagesPlaceholder(variable_name='chat_history'),
		MessagesPlaceholder(variable_name='agent_scratchpad'),
	])

	formatted_prompt = prompt.format_messages(
		chat_history=messages,
		agent_scratchpad=[],
	)

	color_logger.info(
		f'ü§ñ {Colors.BOLD}AGENTIC RAG MODEL + TOOLS:{Colors.RESET}{Colors.BRIGHT_BLUE} Processing with enhanced context and RAG tools',
		Colors.BRIGHT_BLUE,
		model_name=getattr(model, 'model', 'unknown'),
		total_messages=len(formatted_prompt),
		rag_tools_count=len(get_tool_defs(config)),
	)

	# Invoke model with RAG tools bound
	model_with_tools = model.bind_tools(get_tool_defs(config))
	response = await model_with_tools.ainvoke(
		formatted_prompt,
		{
			'system_time': datetime.now(tz=timezone.utc).isoformat(),
			'agentic_mode': True,
			'agentic_rag': True,
			'rag_tools_enabled': True,
			'conversation_id': thread_id,
		},
	)

	processing_time = time.time() - start_time
	color_logger.model_invocation(
		getattr(model, 'model', 'unknown'),
		len(str(response.content)) // 4,  # Token estimate
		processing_time=processing_time,
		response_length=len(str(response.content)),
		agentic_mode=True,
		agentic_rag=True,
		rag_tools_enabled=True,
	)

	return {'messages': response}


async def run_tools(input, config, **kwargs):
	"""Execute tools in Agentic RAG context"""
	start_time = time.time()
	thread_id = config.get('configurable', {}).get('thread_id', 'unknown')

	color_logger.workflow_start('Agentic RAG - Tool Execution', thread_id=thread_id)

	messages = input.get('messages', [])
	tool_calls = []
	if messages:
		last_message = messages[-1]
		if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
			tool_calls = last_message.tool_calls

	tool_node = ToolNode(get_tools(config))
	response = await tool_node.ainvoke(input, config, **kwargs)

	processing_time = time.time() - start_time
	tool_names = [tc.get('name', 'unknown') for tc in tool_calls] if tool_calls else []

	color_logger.tool_execution(
		tool_names,
		processing_time,
		thread_id=thread_id,
		agentic_mode=True,
	)

	return response


def create_agentic_rag_workflow(db_session, config=None):
	"""Create Agentic RAG Workflow with KBRepository and RAG Tools - Always uses RAG with intelligent routing"""
	color_logger.workflow_start(
		'Agentic RAG Workflow Creation with KBRepository + RAG Tools',
		always_rag=True,
		db_session_provided=db_session is not None,
		rag_tools_enabled=True,
	)

	# Initialize workflow configuration
	services_ready = initialize_services(db_session, config)

	color_logger.info(
		f'üöÄ {Colors.BOLD}AGENTIC RAG + TOOLS:{Colors.RESET}{Colors.BRIGHT_GREEN if services_ready else Colors.BRIGHT_RED} {"READY" if services_ready else "FAILED"}',
		Colors.BRIGHT_GREEN if services_ready else Colors.BRIGHT_RED,
		services_initialized=services_ready,
		agentic_rag=True,
		rag_tools_enabled=True,
	)

	# Define Agentic RAG workflow with tools
	workflow = StateGraph(AgentState)

	# Add Agentic RAG nodes with tool support
	workflow.add_node('agent', call_model)
	workflow.add_node('tools', run_tools)

	available_tools = get_tools(config)
	tool_names = [tool.name for tool in available_tools]

	color_logger.info(
		f'üìä {Colors.BOLD}AGENTIC RAG NODES + RAG TOOLS:{Colors.RESET}{Colors.MAGENTA} Workflow nodes configured',
		Colors.MAGENTA,
		node_count=2,
		nodes=['agent', 'tools'],
		available_tools=tool_names,
		rag_tools_count=len([t for t in tool_names if 'query' in t or 'search' in t]),
	)

	# Agentic RAG flow with tool support
	workflow.set_entry_point('agent')

	# Tool handling with RAG support
	workflow.add_conditional_edges('agent', should_continue, {'tools': 'tools', END: END})
	workflow.add_edge('tools', 'agent')

	color_logger.info(
		f'üîó {Colors.BOLD}AGENTIC RAG FLOW + RAG TOOLS:{Colors.RESET}{Colors.CYAN} Always RAG ‚Üí Analysis ‚Üí Tools ‚Üí KB Retrieve ‚Üí Grade ‚Üí Generate',
		Colors.CYAN,
		entry_point='agent',
		always_rag=True,
		agentic_rag=True,
		rag_tools_enabled=True,
	)

	# Compile with memory
	memory = MemorySaver()
	compiled_workflow = workflow.compile(checkpointer=memory)

	color_logger.workflow_complete(
		'Agentic RAG Workflow Creation with KBRepository + RAG Tools',
		time.time(),
		agentic_rag_enabled=True,
		always_rag=True,
		agentic_rag=True,
		rag_tools_enabled=True,
		compilation_successful=True,
	)

	return compiled_workflow


# Create default Agentic RAG workflow
def create_workflow_with_rag(db_session, config=None):
	"""Backward compatibility - now creates Agentic RAG workflow with KBRepository"""
	return create_agentic_rag_workflow(db_session, config)
