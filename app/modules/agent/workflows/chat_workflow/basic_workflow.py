"""
Basic Chat Workflow with integrated Agentic RAG functionality
Advanced workflow with query analysis, routing, and self-correction using Agentic RAG KBRepository
"""

from datetime import datetime, timezone
import time
from typing import Literal
from dotenv import load_dotenv
from langchain_core.messages import SystemMessage
from langchain_core.tools import BaseTool
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.errors import NodeInterrupt
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langgraph.checkpoint.memory import MemorySaver
from pydantic import BaseModel, Field

from .tools.basic_tools import tools
from .state.workflow_state import AgentState
from .config.workflow_config import WorkflowConfig
from .utils.color_logger import get_color_logger, Colors
from .guardrails.manager import ChatWorkflowGuardrailManager

load_dotenv()

# Initialize colorful logger
color_logger = get_color_logger(__name__)


# Router Schema theo LangChain pattern v·ªõi Pydantic BaseModel
class RouterDecision(BaseModel):
	"""Router decision schema for query routing."""

	target: Literal['rag_query', 'direct_agent', 'math_tools', 'general'] = Field(description='Target node ƒë·ªÉ route query ƒë·∫øn')
	explanation: str = Field(description='Explanation cho quy·∫øt ƒë·ªãnh routing')


# Default system prompt for CGSEM AI Assistant
DEFAULT_SYSTEM_PROMPT = """
üåü B·∫°n l√† CGSEM AI Assistant - Tr·ª£ l√Ω th√¥ng minh c·ªßa CLB Truy·ªÅn th√¥ng v√† S·ª± Ki·ªán tr∆∞·ªùng THPT C·∫ßn Giu·ªôc

üìñ V·ªÄ CGSEM:
CLB Truy·ªÅn th√¥ng v√† S·ª± Ki·ªán tr∆∞·ªùng THPT C·∫ßn Giu·ªôc (CGSEM) l√† t·ªï ch·ª©c truy·ªÅn th√¥ng phi l·ª£i nhu·∫≠n ƒë∆∞·ª£c th√†nh l·∫≠p 14/12/2020, v·ªõi kim ch·ªâ nam: "C·ª• th·ªÉ - ƒêa d·∫°ng - VƒÉn minh - C√¥ng b·∫±ng"

üéØ NHI·ªÜM V·ª§ C·ª¶A B·∫†N:
1. H·ªó tr·ª£ th√†nh vi√™n v√† ng∆∞·ªùi quan t√¢m ƒë·∫øn CGSEM
2. Cung c·∫•p th√¥ng tin v·ªÅ ho·∫°t ƒë·ªông, d·ª± √°n c·ªßa CLB
3. H∆∞·ªõng d·∫´n tham gia c√°c ch∆∞∆°ng tr√¨nh truy·ªÅn th√¥ng, s·ª± ki·ªán
4. Truy·ªÅn c·∫£m h·ª©ng v·ªÅ tinh th·∫ßn "ti√™n quy·∫øt, ti√™n phong, s√°ng t·∫°o"
5. Th·ª±c hi·ªán c√°c ph√©p t√≠nh c∆° b·∫£n khi c·∫ßn thi·∫øt
6. S·ª≠ d·ª•ng ki·∫øn th·ª©c t·ª´ t√†i li·ªáu CGSEM ƒë·ªÉ t∆∞ v·∫•n chuy√™n nghi·ªáp

üõ†Ô∏è C√îNG C·ª§ C√ì S·∫¥N:
- Ph√©p t√≠nh: add, subtract, multiply, divide
- RAG: answer_query_collection - Tr·∫£ l·ªùi c√¢u h·ªèi t·ª´ knowledge base c·ªßa CGSEM
- Search: search_knowledge_base - T√¨m ki·∫øm th√¥ng tin trong knowledge base CGSEM

üîç H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG RAG:
- Khi ƒë∆∞·ª£c h·ªèi v·ªÅ th√¥ng tin c·ª• th·ªÉ v·ªÅ CGSEM, s·ª≠ d·ª•ng answer_query_collection
- S·ª≠ d·ª•ng search_knowledge_base ƒë·ªÉ t√¨m ki·∫øm th√¥ng tin tr∆∞·ªõc khi tr·∫£ l·ªùi
- Lu√¥n ∆∞u ti√™n th√¥ng tin t·ª´ knowledge base CGSEM

üó£Ô∏è PHONG C√ÅCH GIAO TI·∫æP:
- Nhi·ªát t√¨nh, t√≠ch c·ª±c v√† truy·ªÅn c·∫£m h·ª©ng
- G·∫ßn g≈©i v·ªõi h·ªçc sinh v√† gi·ªõi tr·∫ª
- Khuy·∫øn kh√≠ch s√°ng t·∫°o v√† d√°m th·ª≠ th√°ch
- Tr·∫£ l·ªùi t·ª± nhi√™n nh∆∞ th√†nh vi√™n th·ª±c s·ª± c·ªßa CGSEM
- KH√îNG ƒê∆Ø·ª¢C S·ª¨ D·ª§NG QUOTE ` `  (INLINE QUOTE) trong c√¢u tr·∫£ l·ªùi V√å N√ì S·∫º L√ÄM L·ªñI H·ªÜ TH·ªêNG NGHI√äM TR·ªåNG

‚ö° PH∆Ø∆†NG CH√ÇM: "CGSEM - ti√™n quy·∫øt, ti√™n phong, s√°ng t·∫°o"

B·∫°n lu√¥n ph√¢n t√≠ch query v√† s·ª≠ d·ª•ng c√¥ng c·ª• ph√π h·ª£p nh·∫•t ƒë·ªÉ tr·∫£ l·ªùi v·ªõi tinh th·∫ßn nhi·ªát huy·∫øt c·ªßa tu·ªïi tr·∫ª CGSEM!
"""

# Router system prompt cho CGSEM theo meobeo-ai-rule standards
ROUTER_SYSTEM_PROMPT = """
üß≠ B·∫°n l√† Router Agent th√¥ng minh cho h·ªá th·ªëng CGSEM AI Assistant. Nhi·ªám v·ª• c·ªßa b·∫°n l√† ph√¢n t√≠ch user query v√† quy·∫øt ƒë·ªãnh route ph√π h·ª£p nh·∫•t.

üéØ TARGET NODES AVAILABLE:
1. "rag_query" - Cho c√¢u h·ªèi c·∫ßn t√¨m ki·∫øm th√¥ng tin t·ª´ knowledge base ho·∫∑c file ng∆∞·ªùi d√πng ƒë√£ upload
2. "direct_agent" - Cho c√¢u h·ªèi ƒë∆°n gi·∫£n, general knowledge, chat th√¥ng th∆∞·ªùng, ch√†o h·ªèi
3. "math_tools" - Cho c√°c ph√©p t√≠nh, calculation, t√≠nh to√°n c∆° b·∫£n
4. "general" - Cho c√°c tr∆∞·ªùng h·ª£p kh√°c

üìã QUY T·∫ÆC ROUTING:
- RAG Query: Khi user h·ªèi v·ªÅ:
    * **Th√¥ng tin t·ª´ file/t√†i li·ªáu ƒë√£ upload (∆∞u ti√™n cao nh·∫•t)**
    * N·ªôi dung c·ª• th·ªÉ m√† c√≥ th·ªÉ c√≥ trong file ng∆∞·ªùi d√πng
    * Th√¥ng tin v·ªÅ CGSEM ch·ªâ khi user ƒë·ªÅ c·∫≠p r√µ r√†ng v·ªÅ CLB
    * Ki·∫øn th·ª©c chuy√™n m√¥n c·∫ßn tra c·ª©u t·ª´ t√†i li·ªáu
    * **Khi user h·ªèi v·ªÅ th√¥ng tin c·ª• th·ªÉ m√† c√≥ th·ªÉ ƒë·∫øn t·ª´ file ƒë√£ upload**

- Direct Agent: 
    * Chat th√¥ng th∆∞·ªùng v√† ch√†o h·ªèi
    * C√¢u h·ªèi general knowledge kh√¥ng c·∫ßn tra c·ª©u file
    * Th√¥ng tin chung m√† AI c√≥ th·ªÉ tr·∫£ l·ªùi t·ª´ ki·∫øn th·ª©c c√≥ s·∫µn
    * Khi ch·∫Øc ch·∫Øn kh√¥ng c·∫ßn th√¥ng tin t·ª´ file ng∆∞·ªùi d√πng

- Math Tools: 
    * Ph√©p t√≠nh to√°n h·ªçc c∆° b·∫£n
    * Calculations v√† computations

- General: 
    * C√°c tr∆∞·ªùng h·ª£p ƒë·∫∑c bi·ªát kh√°c

‚ö†Ô∏è NGUY√äN T·∫ÆC: ∆Øu ti√™n route "rag_query" khi user h·ªèi v·ªÅ th√¥ng tin c·ª• th·ªÉ c√≥ th·ªÉ ƒë·∫øn t·ª´ file ƒë√£ upload, kh√¥ng bias v·ªÅ th√¥ng tin CGSEM tr·ª´ khi user ƒë·ªÅ c·∫≠p r√µ r√†ng.

üí° Ph√¢n t√≠ch context ƒë·ªÉ x√°c ƒë·ªãnh user ƒëang h·ªèi v·ªÅ file c·ªßa h·ªç hay th√¥ng tin general!
"""

# Initialize the default model
model = ChatGoogleGenerativeAI(model='gemini-2.0-flash-lite', temperature=0)

# Global workflow config
workflow_config = None

# Global guardrail manager
guardrail_manager = None


def initialize_services(db_session, config=None):
	"""Initialize workflow configuration for Agentic RAG"""
	global workflow_config, guardrail_manager

	color_logger.workflow_start(
		'Agentic RAG Workflow Configuration',
		db_session_id=id(db_session),
		config_provided=config is not None,
	)

	try:
		workflow_config = config or WorkflowConfig.from_env()

		# Initialize Guardrail Manager
		guardrail_config = {
			'enable_input_guardrails': True,
			'enable_output_guardrails': True,
			'max_input_length': 5000,
			'strict_mode': False,
		}
		guardrail_manager = ChatWorkflowGuardrailManager(guardrail_config)

		color_logger.info(
			f'üìã {Colors.BOLD}CONFIG:{Colors.RESET}{Colors.CYAN} Agentic RAG workflow configured',
			Colors.CYAN,
			model_name=workflow_config.model_name,
			collection_name=workflow_config.collection_name,
		)

		color_logger.info(
			f'üõ°Ô∏è {Colors.BOLD}GUARDRAILS:{Colors.RESET}{Colors.CYAN} Guardrail system initialized',
			Colors.CYAN,
			input_guardrails=len(guardrail_manager.engine.input_guardrails),
			output_guardrails=len(guardrail_manager.engine.output_guardrails),
		)

		color_logger.workflow_complete(
			'Agentic RAG Workflow Configuration',
			time.time(),
			services_count=2,  # workflow + guardrails
			status='success',
		)
		return True
	except Exception as e:
		color_logger.error(
			f'Failed to initialize Agentic RAG workflow config: {str(e)}',
			error_type=type(e).__name__,
			traceback_available=True,
		)
		return False


def should_continue(state):
	"""Determine if the agent should continue with tool execution or end."""
	messages = state.get('messages', [])
	if not messages:
		return END

	last_message = messages[-1]
	if not hasattr(last_message, 'tool_calls') or not last_message.tool_calls:
		return END
	else:
		return 'tools'


def get_tool_defs(config):
	"""Get tool definitions for binding to the model."""
	from .tools.basic_tools import get_tool_definitions

	return get_tool_definitions(config)


def get_tools(config):
	"""Get tool instances for the tool node."""
	from .tools.basic_tools import get_tools as get_basic_tools

	return get_basic_tools(config)


async def rag_query_node(state, config):
	"""RAG Query Node - B·∫Øt bu·ªôc search knowledge base tr∆∞·ªõc khi ƒë∆∞a cho agent"""
	start_time = time.time()
	thread_id = config.get('configurable', {}).get('thread_id', 'unknown')

	color_logger.workflow_start(
		'RAG Query Node - Mandatory Knowledge Retrieval',
		thread_id=thread_id,
		mandatory_rag=True,
	)

	# Get user message ƒë·ªÉ l√†m query
	messages = state.get('messages', [])
	if not messages:
		return state

	# L·∫•y message cu·ªëi c√πng t·ª´ user
	user_query = None
	for msg in reversed(messages):
		if hasattr(msg, 'content') and msg.content:
			user_query = msg.content
			break

	if not user_query:
		color_logger.warning('No user query found for RAG')
		return state

	# Th·ª±c hi·ªán RAG query b·∫Øt bu·ªôc
	try:
		# Collection ID s·ª≠ d·ª•ng conversation_id format
		collection_id = f'conversation_{thread_id}'

		color_logger.info(
			f'üîç {Colors.BOLD}MANDATORY RAG:{Colors.RESET}{Colors.BRIGHT_YELLOW} Searching knowledge base',
			Colors.BRIGHT_YELLOW,
			query_preview=user_query[:100],
			collection_id=collection_id,
		)

		# Import RAG dependencies
		from app.modules.agentic_rag.agent.rag_graph import RAGAgentGraph
		from app.modules.agentic_rag.repositories.kb_repo import KBRepository

		# Initialize RAG agent for the collection
		kb_repo = KBRepository(collection_name=collection_id)
		rag_agent = RAGAgentGraph(kb_repo=kb_repo, collection_id=collection_id)

		# Process the query
		result = await rag_agent.answer_query(query=user_query, collection_id=collection_id)

		# Format the response with answer and sources
		answer = result.get('answer', 'No answer found')
		sources = result.get('sources', [])

		# Create a formatted response that includes source information
		rag_response = answer

		if sources:
			rag_response += '\n\nüìö Sources:'
			for i, source in enumerate(sources, 1):
				source_info = f'\n{i}. Document ID: {source.get("id", "Unknown")}'
				if 'metadata' in source and 'source' in source['metadata']:
					source_info += f' (File: {source["metadata"]["source"]})'
				rag_response += source_info

		color_logger.info(
			f"[RAG Query] RAG query completed for collection '{collection_id}' with {len(sources)} sources",
			source_count=len(sources),
			answer_length=len(answer),
		)

		# L∆∞u RAG context v√†o state
		rag_context = [rag_response] if rag_response else []

		color_logger.info(
			f'üß† {Colors.BOLD}RAG CONTEXT RETRIEVED:{Colors.RESET}{Colors.BRIGHT_GREEN} Context length: {len(rag_response) if rag_response else 0}',
			Colors.BRIGHT_GREEN,
			context_available=bool(rag_response),
			response_preview=rag_response[:200] if rag_response else 'No context',
		)

		# Update state v·ªõi RAG context
		updated_state = {
			**state,
			'rag_context': rag_context,
			'retrieval_quality': 'good' if rag_response else 'no_results',
			'agentic_rag_used': True,
			'mandatory_rag_complete': True,
		}

		processing_time = time.time() - start_time
		color_logger.workflow_complete(
			'RAG Query Node - Mandatory Knowledge Retrieval',
			processing_time,
			rag_context_retrieved=bool(rag_response),
			context_length=len(rag_response) if rag_response else 0,
		)

		return updated_state

	except Exception as e:
		color_logger.error(
			f'RAG Query Node failed: {str(e)}',
			error_type=type(e).__name__,
		)
		# Continue v·ªõi empty context thay v√¨ fail
		return {
			**state,
			'rag_context': [],
			'retrieval_quality': 'error',
			'agentic_rag_used': False,
			'mandatory_rag_complete': True,
		}


async def call_model(state, config):
	"""Agentic RAG - Enhanced Model Call v·ªõi RAG Context c√≥ s·∫µn v√† Persona Support"""
	start_time = time.time()
	thread_id = config.get('configurable', {}).get('thread_id', 'unknown')

	color_logger.workflow_start(
		'Agentic RAG - Model Invocation with Pre-loaded Context and Persona',
		thread_id=thread_id,
		has_context=bool(state.get('rag_context')),
		mandatory_rag_complete=state.get('mandatory_rag_complete', False),
		agentic_rag_enabled=True,
		persona_enabled=workflow_config.persona_enabled if workflow_config else False,
	)

	# Get system prompt - Use persona if enabled
	if workflow_config and workflow_config.persona_enabled:
		persona_prompt = workflow_config.get_persona_prompt()
		persona_name = workflow_config.get_persona_name()

		color_logger.info(
			f'üé≠ {Colors.BOLD}PERSONA ACTIVATED:{Colors.RESET}{Colors.BRIGHT_MAGENTA} {persona_name}',
			Colors.BRIGHT_MAGENTA,
			persona_name=persona_name,
			persona_type=(workflow_config.persona_type.value if workflow_config.persona_type else 'none'),
		)
		system = persona_prompt
	else:
		system = config.get('configurable', {}).get('system_prompt', DEFAULT_SYSTEM_PROMPT)

	# Enhanced system prompt for Agentic RAG v·ªõi CGSEM context v√† Persona
	persona_info = ''
	if workflow_config and workflow_config.persona_enabled:
		persona_info = f"""
üé≠ PERSONA ACTIVE: {workflow_config.get_persona_name()}
Persona Type: {workflow_config.persona_type.value if workflow_config.persona_type else 'none'}
"""

	agentic_system = f"""{system}

ü§ñ B·∫†N L√Ä CGSEM AGENTIC RAG AI v·ªõi KNOWLEDGE CONTEXT - Context ƒë√£ ƒë∆∞·ª£c load s·∫µn:{persona_info}

üõ†Ô∏è BASIC TOOLS AVAILABLE:
- add(a, b): C·ªông hai s·ªë
- subtract(a, b): Tr·ª´ hai s·ªë  
- multiply(a, b): Nh√¢n hai s·ªë
- divide(a, b): Chia hai s·ªë

üìä CONVERSATION CONTEXT: {thread_id}
üìà RAG Status: {state.get('retrieval_quality', 'unknown')}
‚úÖ Context Pre-loaded: {state.get('mandatory_rag_complete', False)}
üî• Agentic RAG: {state.get('agentic_rag_used', True)}

üåü H∆Ø·ªöNG D·∫™N ƒê·∫∂C BI·ªÜT CHO CGSEM:
1. üìö CONTEXT CGSEM ƒê√É C√ì S·∫¥N: S·ª≠ d·ª•ng knowledge context CGSEM ƒë∆∞·ª£c cung c·∫•p b√™n d∆∞·ªõi l√†m ngu·ªìn ch√≠nh
2. üßÆ T√çNH TO√ÅN: S·ª≠ d·ª•ng math tools khi c·∫ßn th·ª±c hi·ªán ph√©p t√≠nh cho d·ª± √°n, s·ª± ki·ªán
3. üí° K·∫øt h·ª£p context CGSEM v·ªõi ki·∫øn th·ª©c v·ªÅ truy·ªÅn th√¥ng, s·ª± ki·ªán ƒë·ªÉ tr·∫£ l·ªùi to√†n di·ªán
4. üéØ TR·∫¢ L·ªúI T·ª∞ NHI√äN: KH√îNG ghi "(Theo th√¥ng tin t·ª´ context)" - tr·∫£ l·ªùi nh∆∞ th√†nh vi√™n th·ª±c s·ª± c·ªßa CGSEM
5. üó£Ô∏è N√≥i nh∆∞ th·ªÉ b·∫°n l√† m·ªôt ph·∫ßn c·ªßa CLB CGSEM, s·ª≠ d·ª•ng "ch√∫ng m√¨nh", "CLB c·ªßa m√¨nh", "team CGSEM"
6. ‚ö° Context CGSEM ƒë√£ ƒë∆∞·ª£c retrieve t·ª± ƒë·ªông, kh√¥ng c·∫ßn g·ªçi th√™m RAG tools
7. üé≠ Gi·ªØ tinh th·∫ßn nhi·ªát huy·∫øt, s√°ng t·∫°o v√† truy·ªÅn c·∫£m h·ª©ng c·ªßa CGSEM
8. üåà Lu√¥n khuy·∫øn kh√≠ch tham gia ho·∫°t ƒë·ªông v√† ph√°t tri·ªÉn b·∫£n th√¢n c√πng CGSEM
"""

	# Add RAG context if available (from mandatory RAG query)
	rag_context = state.get('rag_context')
	if rag_context:
		context_quality = state.get('retrieval_quality', 'unknown')
		context_length = sum(len(ctx) for ctx in rag_context)

		color_logger.info(
			f'üß† {Colors.BOLD}PRE-LOADED RAG CONTEXT:{Colors.RESET}{Colors.BRIGHT_YELLOW} Quality={context_quality}',
			Colors.BRIGHT_YELLOW,
			sources_count=len(rag_context),
			total_context_length=context_length,
			quality=context_quality,
			pre_loaded=True,
		)

		enhanced_system = f'{agentic_system}\n\nüîó KI·∫æN TH·ª®C T·ª™ CGSEM KNOWLEDGE BASE (Quality: {context_quality}):\n' + '\n'.join(rag_context)
	else:
		color_logger.info(
			f'üìù {Colors.BOLD}NO RAG CONTEXT:{Colors.RESET}{Colors.DIM} No context retrieved from knowledge base',
			Colors.DIM,
			context_available=False,
		)
		enhanced_system = agentic_system

	# Prepare messages
	messages = state.get('messages', [])
	if not messages:
		return {'messages': [SystemMessage(content=enhanced_system)]}

	# Create enhanced prompt
	prompt = ChatPromptTemplate.from_messages([
		('system', enhanced_system),
		MessagesPlaceholder(variable_name='chat_history'),
		MessagesPlaceholder(variable_name='agent_scratchpad'),
	])

	formatted_prompt = prompt.format_messages(
		chat_history=messages,
		agent_scratchpad=[],
	)

	color_logger.info(
		f'ü§ñ {Colors.BOLD}AGENTIC RAG MODEL + TOOLS:{Colors.RESET}{Colors.BRIGHT_BLUE} Processing with enhanced context and math tools',
		Colors.BRIGHT_BLUE,
		model_name=getattr(model, 'model', 'unknown'),
		total_messages=len(formatted_prompt),
		math_tools_count=len(get_tool_defs(config)),
	)

	# Invoke model with RAG tools bound
	model_with_tools = model.bind_tools(get_tool_defs(config))
	response = await model_with_tools.ainvoke(
		formatted_prompt,
		{
			'system_time': datetime.now(tz=timezone.utc).isoformat(),
			'agentic_mode': True,
			'agentic_rag': True,
			'rag_tools_enabled': True,
			'conversation_id': thread_id,
		},
	)

	processing_time = time.time() - start_time
	color_logger.model_invocation(
		getattr(model, 'model', 'unknown'),
		len(str(response.content)) // 4,  # Token estimate
		processing_time=processing_time,
		response_length=len(str(response.content)),
		agentic_mode=True,
		agentic_rag=True,
		rag_tools_enabled=True,
	)

	return {'messages': response}


async def run_tools(input, config, **kwargs):
	"""Execute tools in Agentic RAG context"""
	start_time = time.time()
	thread_id = config.get('configurable', {}).get('thread_id', 'unknown')

	color_logger.workflow_start('Agentic RAG - Tool Execution', thread_id=thread_id)

	messages = input.get('messages', [])
	tool_calls = []
	if messages:
		last_message = messages[-1]
		if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
			tool_calls = last_message.tool_calls

	tool_node = ToolNode(get_tools(config))
	response = await tool_node.ainvoke(input, config, **kwargs)

	processing_time = time.time() - start_time
	tool_names = [tc.get('name', 'unknown') for tc in tool_calls] if tool_calls else []

	color_logger.tool_execution(
		tool_names,
		processing_time,
		thread_id=thread_id,
		agentic_mode=True,
	)

	return response


async def router_node(state, config):
	"""Router Node - Intelligent query routing v·ªõi LLM router s·ª≠ d·ª•ng structured output + Input Guardrails"""
	start_time = time.time()
	thread_id = config.get('configurable', {}).get('thread_id', 'unknown')

	color_logger.workflow_start(
		'Router Node - Intelligent Query Routing with Input Guardrails',
		thread_id=thread_id,
		router_enabled=True,
		guardrails_enabled=True,
	)

	# Get user message ƒë·ªÉ ph√¢n t√≠ch routing
	messages = state.get('messages', [])
	if not messages:
		color_logger.warning('No messages found for routing')
		return {
			**state,
			'router_decision': {'target': 'general', 'explanation': 'No user input'},
		}

	# L·∫•y message cu·ªëi c√πng t·ª´ user
	user_query = None
	for msg in reversed(messages):
		if hasattr(msg, 'content') and msg.content:
			user_query = msg.content
			break

	if not user_query:
		color_logger.warning('No user query found for routing')
		return {
			**state,
			'router_decision': {'target': 'general', 'explanation': 'Empty query'},
		}

	# üõ°Ô∏è APPLY INPUT GUARDRAILS
	try:
		if guardrail_manager:
			color_logger.info(
				f'üõ°Ô∏è {Colors.BOLD}INPUT GUARDRAILS:{Colors.RESET}{Colors.YELLOW} Checking user input',
				Colors.YELLOW,
				query_length=len(user_query),
			)

			# Check input v·ªõi guardrails
			guardrail_context = {
				'thread_id': thread_id,
				'user_id': config.get('configurable', {}).get('user_id', 'unknown'),
				'conversation_step': 'router_input',
			}

			guardrail_result = guardrail_manager.check_user_input(user_query, guardrail_context)

			# Log guardrail results
			if guardrail_result.violations:
				violation_details = [f'{v.rule_name}: {v.message}' for v in guardrail_result.violations]
				color_logger.warning(
					f'üö® Input Guardrail Violations: {len(guardrail_result.violations)} found',
					violations=violation_details,
				)

			# Block n·∫øu guardrails failed
			if not guardrail_result.passed:
				color_logger.error(
					f'üö´ Input BLOCKED by guardrails',
					violation_count=len(guardrail_result.violations),
				)

				return {
					**state,
					'router_decision': {
						'target': 'general',
						'explanation': 'Input blocked by content safety guardrails',
					},
					'routing_complete': True,
					'guardrail_blocked': True,
					'guardrail_violations': [v.__dict__ for v in guardrail_result.violations],
				}

			# S·ª≠ d·ª•ng modified content n·∫øu c√≥
			if guardrail_result.modified_content:
				user_query = guardrail_result.modified_content
				color_logger.info(
					f'‚úèÔ∏è Input modified by guardrails',
					original_length=len(messages[-1].content),
					modified_length=len(user_query),
				)

			color_logger.info(
				f'‚úÖ Input passed guardrails',
				violations_count=len(guardrail_result.violations),
				processing_time=f'{guardrail_result.processing_time:.3f}s',
			)

	except Exception as e:
		color_logger.error(
			f'Guardrail check failed: {str(e)}',
			error_type=type(e).__name__,
		)
		# Continue without guardrails on error

	try:
		# Create router prompt theo LangChain pattern
		router_prompt = ChatPromptTemplate.from_messages([
			('system', ROUTER_SYSTEM_PROMPT),
			(
				'human',
				'User query: {input}\n\nAnalyze this query and determine the best routing target.',
			),
		])

		# Create router chain v·ªõi structured output
		router_chain = router_prompt | model.with_structured_output(RouterDecision)

		color_logger.info(
			f'üß≠ {Colors.BOLD}ROUTER ANALYSIS:{Colors.RESET}{Colors.BRIGHT_YELLOW} Analyzing query for routing',
			Colors.BRIGHT_YELLOW,
			query_preview=user_query[:100],
			available_targets=['rag_query', 'direct_agent', 'math_tools', 'general'],
		)

		# Execute router decision
		router_result = await router_chain.ainvoke({'input': user_query})

		target = router_result.target if hasattr(router_result, 'target') else 'general'
		explanation = router_result.explanation if hasattr(router_result, 'explanation') else 'Default routing'

		color_logger.info(
			f'üéØ {Colors.BOLD}ROUTER DECISION:{Colors.RESET}{Colors.BRIGHT_GREEN} Target={target}',
			Colors.BRIGHT_GREEN,
			target=target,
			explanation=explanation,
			query_length=len(user_query),
		)

		# Update state v·ªõi router decision
		updated_state = {
			**state,
			'router_decision': {'target': target, 'explanation': explanation},
			'routing_complete': True,
		}

		processing_time = time.time() - start_time
		color_logger.workflow_complete(
			'Router Node - Intelligent Query Routing with Input Guardrails',
			processing_time,
			target_selected=target,
			routing_successful=True,
			guardrails_passed=True,
		)

		return updated_state

	except Exception as e:
		color_logger.error(
			f'Router Node failed: {str(e)}',
			error_type=type(e).__name__,
		)

		# Fallback routing on error
		return {
			**state,
			'router_decision': {
				'target': 'general',
				'explanation': f'Router error: {str(e)[:100]}',
			},
			'routing_complete': True,
		}


def router_conditional_edge(state):
	"""Conditional edge function for router decisions"""
	router_decision = state.get('router_decision', {})
	target = router_decision.get('target', 'general') if isinstance(router_decision, dict) else 'general'

	# Map router targets to actual nodes
	target_mapping = {
		'rag_query': 'rag_query',
		'direct_agent': 'agent',
		'math_tools': 'agent',  # Will use tools via agent
		'general': 'agent',
	}

	actual_target = target_mapping.get(target, 'agent')

	color_logger.info(
		f'üîÄ {Colors.BOLD}ROUTER EDGE:{Colors.RESET}{Colors.CYAN} {target} ‚Üí {actual_target}',
		Colors.CYAN,
		logical_target=target,
		actual_node=actual_target,
	)

	return actual_target


def create_agentic_rag_workflow(db_session, config=None):
	"""Create Agentic RAG Workflow with Router + KBRepository and RAG Tools - Intelligent routing v·ªõi LLM router v√† Persona support"""
	color_logger.workflow_start(
		'Agentic RAG Workflow Creation with Router + KBRepository + RAG Tools + Persona',
		router_enabled=True,
		intelligent_routing=True,
		db_session_provided=db_session is not None,
		rag_tools_enabled=True,
		persona_enabled=workflow_config.persona_enabled if workflow_config else False,
	)

	# Initialize workflow configuration
	services_ready = initialize_services(db_session, config)

	# Log persona information if enabled
	persona_info = ''
	if workflow_config and workflow_config.persona_enabled:
		persona_name = workflow_config.get_persona_name()
		persona_info = f' + {persona_name} Persona'

		color_logger.info(
			f'üé≠ {Colors.BOLD}PERSONA ENABLED:{Colors.RESET}{Colors.BRIGHT_MAGENTA} {persona_name}',
			Colors.BRIGHT_MAGENTA,
			persona_name=persona_name,
			persona_type=(workflow_config.persona_type.value if workflow_config.persona_type else 'none'),
		)

	color_logger.info(
		f'üöÄ {Colors.BOLD}AGENTIC RAG + TOOLS{persona_info}:{Colors.RESET}{Colors.BRIGHT_GREEN if services_ready else Colors.BRIGHT_RED} {"READY" if services_ready else "FAILED"}',
		Colors.BRIGHT_GREEN if services_ready else Colors.BRIGHT_RED,
		services_initialized=services_ready,
		agentic_rag=True,
		rag_tools_enabled=True,
		persona_enabled=workflow_config.persona_enabled if workflow_config else False,
	)

	# Define Agentic RAG workflow with Router and tools
	workflow = StateGraph(AgentState)

	# Add Router and Agentic RAG nodes
	workflow.add_node('router', router_node)  # Router node - entry point
	workflow.add_node('rag_query', rag_query_node)  # RAG query node
	workflow.add_node('agent', call_model)  # Agent node
	workflow.add_node('tools', run_tools)  # Tools node

	available_tools = get_tools(config)
	tool_names = [tool.name for tool in available_tools]

	color_logger.info(
		f'üìä {Colors.BOLD}ROUTER + AGENTIC RAG WORKFLOW NODES:{Colors.RESET}{Colors.MAGENTA} Workflow nodes configured',
		Colors.MAGENTA,
		node_count=4,
		nodes=['router', 'rag_query', 'agent', 'tools'],
		available_tools=tool_names,
		math_tools_count=len([t for t in tool_names if t in ['add', 'subtract', 'multiply', 'divide']]),
		router_enabled=True,
		intelligent_routing=True,
	)

	# Router-based flow: router ‚Üí (rag_query | agent) ‚Üí tools (if needed) ‚Üí agent ‚Üí END
	workflow.set_entry_point('router')  # B·∫Øt ƒë·∫ßu v·ªõi Router

	# Router ‚Üí conditional routing to rag_query or agent
	workflow.add_conditional_edges('router', router_conditional_edge, {'rag_query': 'rag_query', 'agent': 'agent'})

	# RAG query ‚Üí agent (when RAG is needed)
	workflow.add_edge('rag_query', 'agent')

	# Agent ‚Üí tools (if needed) or END
	workflow.add_conditional_edges('agent', should_continue, {'tools': 'tools', END: END})
	workflow.add_edge('tools', 'agent')

	color_logger.info(
		f'üîó {Colors.BOLD}INTELLIGENT ROUTER FLOW:{Colors.RESET}{Colors.CYAN} Router ‚Üí (RAG Query | Direct Agent) ‚Üí Math Tools (if needed) ‚Üí Agent ‚Üí END',
		Colors.CYAN,
		entry_point='router',
		router_enabled=True,
		intelligent_routing=True,
		agentic_rag=True,
		math_tools_enabled=True,
	)

	# Compile with memory
	memory = MemorySaver()
	compiled_workflow = workflow.compile(checkpointer=memory)

	color_logger.workflow_complete(
		'Agentic RAG Workflow Creation with Router + KBRepository + RAG Tools + Persona',
		time.time(),
		router_enabled=True,
		intelligent_routing=True,
		agentic_rag_enabled=True,
		agentic_rag=True,
		rag_tools_enabled=True,
		persona_enabled=workflow_config.persona_enabled if workflow_config else False,
		persona_name=(workflow_config.get_persona_name() if workflow_config and workflow_config.persona_enabled else None),
		compilation_successful=True,
	)

	return compiled_workflow


# Create default Agentic RAG workflow
def create_workflow_with_rag(db_session, config=None):
	"""Backward compatibility - now creates Agentic RAG workflow with KBRepository"""
	return create_agentic_rag_workflow(db_session, config)
